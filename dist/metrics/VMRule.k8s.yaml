apiVersion: operator.victoriametrics.com/v1beta1
kind: VMRule
metadata:
  labels:
    alerts.cmdcentral.xyz/kind: metrics
  name: k8s
  namespace: metrics
spec:
  groups:
    - name: k8s
      rules:
        - alert: KubernetesNodeReady
          annotations:
            description: |-
              Node {{ $labels.node }} has been unready for a long time
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes Node ready (instance {{ $labels.instance }})
          expr: kube_node_status_condition{condition="Ready",status="true"} == 0
          for: 10m
          labels:
            priority: "1"
            push_notify: "true"
        - alert: KubernetesMemoryPressure
          annotations:
            description: |-
              {{ $labels.node }} has MemoryPressure condition
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes memory pressure (instance {{ $labels.instance }})
          expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
          for: 2m
          labels:
            priority: "1"
        - alert: KubernetesDiskPressure
          annotations:
            description: |-
              {{ $labels.node }} has DiskPressure condition
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes disk pressure (instance {{ $labels.instance }})
          expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
          for: 2m
          labels:
            priority: "1"
        - alert: KubernetesContainerOomKilled
          annotations:
            description: |-
              Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }}.
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes container oom killed (instance {{ $labels.instance }})
          expr: sum by(namespace, pod) (kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}) > 0
          for: 0m
          labels:
            priority: "0"
            push_notify: "true"
        - alert: KubernetesPersistentvolumeclaimPending
          annotations:
            description: |-
              PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})
          expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
          for: 2m
          labels:
            priority: "-1"
        - alert: KubernetesVolumeOutOfDiskSpace
          annotations:
            description: |-
              Volume is almost full (< 10% left)
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes Volume out of disk space (instance {{ $labels.instance }})
          expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
          for: 2m
          labels:
            priority: "0"
        - alert: KubernetesPersistentvolumeError
          annotations:
            description: |-
              Persistent volume is in bad state
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes PersistentVolume error (instance {{ $labels.instance }})
          expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending", job="kube-state-metrics"} > 0
          for: 0m
          labels:
            priority: "1"
        - alert: KubernetesStatefulsetDown
          annotations:
            description: |-
              A StatefulSet went down
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes StatefulSet down (instance {{ $labels.instance }})
          expr: (kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas_current) != 1
          for: 1m
          labels:
            priority: "1"
        - alert: KubernetesHpaScaleCapability
          annotations:
            description: |-
              The maximum number of desired Pods has been hit
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes HPA scale capability (instance {{ $labels.instance }})
          expr: kube_horizontalpodautoscaler_status_desired_replicas >= kube_horizontalpodautoscaler_spec_max_replicas
          for: 2m
          labels:
            priority: "-1"
        - alert: KubernetesPodNotHealthy
          annotations:
            description: |-
              Pod has been in a non-ready state for longer than 15 minutes.
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: "Kubernetes Pod not healthy (namespace: {{ $labels.namespace }}; pod: {{ $labels.pod }})"
          expr: sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed",pod!~".*maintain-job.*"}) > 0
          for: 5m
          labels:
            priority: "1"
            push_notify: "true"
        - alert: KubernetesPodCrashLooping
          annotations:
            description: |-
              Pod {{ $labels.pod }} is crash looping
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes pod crash looping (instance {{ $labels.instance }})
          expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
          for: 15m
          labels:
            priority: "0"
            push_notify: "true"
        - alert: KubernetesDeploymentGenerationMismatch
          annotations:
            description: |-
              A Deployment has failed but has not been rolled back.
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes Deployment generation mismatch (instance {{ $labels.instance }})
          expr: kube_deployment_status_observed_generation != kube_deployment_metadata_generation
          for: 10m
          labels:
            priority: "1"
        - alert: KubernetesStatefulsetGenerationMismatch
          annotations:
            description: |-
              A StatefulSet has failed but has not been rolled back.
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes StatefulSet generation mismatch (instance {{ $labels.instance }})
          expr: kube_statefulset_status_observed_generation != kube_statefulset_metadata_generation
          for: 10m
          labels:
            priority: "1"
        - alert: KubernetesStatefulsetUpdateNotRolledOut
          annotations:
            description: |-
              StatefulSet update has not been rolled out.
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes StatefulSet update not rolled out (instance {{ $labels.instance }})
          expr: max without (revision) (kube_statefulset_status_current_revision unless kube_statefulset_status_update_revision) * (kube_statefulset_replicas != kube_statefulset_status_replicas_updated)
          for: 10m
          labels:
            priority: "0"
        - alert: KubernetesDaemonsetRolloutStuck
          annotations:
            description: |-
              Some Pods of DaemonSet are not scheduled or not ready
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes DaemonSet rollout stuck (instance {{ $labels.instance }})
          expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled > 0
          for: 10m
          labels:
            priority: "0"
            push_notify: "true"
        - alert: KubernetesDaemonsetMisscheduled
          annotations:
            description: |-
              Some DaemonSet Pods are running where they are not supposed to run
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes DaemonSet misscheduled (instance {{ $labels.instance }})
          expr: kube_daemonset_status_number_misscheduled > 0
          for: 1m
          labels:
            priority: "1"
        - alert: KubernetesApiServerErrors
          annotations:
            description: |-
              Kubernetes API server is experiencing high error rate
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes API server errors
          expr: sum(rate(apiserver_request_total{job="apiserver",code=~"(?:5..)"}[1m])) / sum(rate(apiserver_request_total{job="apiserver"}[1m])) * 100 > 3
          for: 2m
          labels:
            priority: "1"
        - alert: KubernetesApiClientErrors
          annotations:
            description: |-
              Kubernetes API client is experiencing high error rate
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
            summary: Kubernetes API client errors (instance {{ $labels.instance }})
          expr: (sum(rate(rest_client_requests_total{code=~"(4|5)..",job!="metrics-victoria-metrics-operator"}[1m])) by (instance, job) / sum(rate(rest_client_requests_total[1m])) by (instance, job)) * 100 > 1
          for: 2m
          labels:
            priority: "1"
        - alert: KubernetesClientCertificateExpiresNextWeek
          annotations:
            description: |-
              A client certificate used to authenticate to the apiserver is expiring next week.

              VALUE = {{ $value }}

              LABELS = {{ $labels }}
            summary: Kubernetes client certificate expires next week
          expr: sum by (job) (apiserver_client_certificate_expiration_seconds_count{job="apiserver"}) > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 7*24*60*60
          for: 0m
          labels:
            priority: "0"
        - alert: KubernetesApiServerLatency
          annotations:
            description: |-
              Kubernetes API server has a 99th percentile latency of {{ $value }} seconds for {{ $labels.verb }}.

              VALUE = {{ $value }}
              LABELS = {{ $labels }}
            summary: Kubernetes API server latency
          expr: histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{subresource!="log",verb!~"(?:CONNECT|WATCHLIST|WATCH|PROXY)"} [10m])) WITHOUT (instance, resource)) / 1e+06 > 1
          for: 2m
          labels:
            priority: "0"
        - alert: KubeRebootRequired
          annotations:
            description: Machine(s) require being rebooted, probably due to kernel update.
            impact: Cluster nodes more vulnerable to security exploits. Eventually, no disk space left.
            summary: "{{ $labels.node }} requires being rebooted, and the reboot daemon has failed to do so for 4 hours"
          expr: max(kured_reboot_required) by (node) != 0
          for: 4h
          labels:
            priority: "0"
            push_notify: "true"
        - alert: KubeletVersionSkew
          annotations:
            summary: "{{ $value }} nodes are not running the same kubelet version as the others"
          expr: min(count(kube_node_info) by (kubelet_version)) < count(kube_node_info)
          for: 1h
          labels:
            priority: "0"
            push_notify: "true"
        - alert: KubernetesPodCpuThrottling
          annotations:
            summary: Pod {{ $labels.pod }} in {{ $labels.namespace }} seeing 25% of CFS periods throttled.
          expr: increase(container_cpu_cfs_throttled_periods_total{}[$__rate_interval]) / increase(container_cpu_cfs_periods_total{}[$__rate_interval]) * 100 > 25
          for: 30m
          labels:
            priority: "0"
            push_notify: "true"
